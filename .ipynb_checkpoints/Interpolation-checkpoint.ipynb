{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get GTZAN and MusiCNN-MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import essentia.standard as es\n",
    "from essentia import Pool\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(42)\n",
    "###############################################################################################\n",
    "\n",
    "# Please first specify the path of your GTZAN dataset if it is already downloaded in your system.\n",
    "    # Otherwise leave 'data' or the desired path where we will download the dataset.\n",
    "\n",
    "GTZAN_path = 'data'\n",
    "#GTZAN_path = <your_path>\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "# TensorflowPredictMusiCNN expects mono 16kHz sample rate inputs. Resample needed\n",
    "resample = es.Resample(inputSampleRate=22050, outputSampleRate=16000, quality=0)\n",
    "\n",
    "# Download dataset from torchaudio\n",
    "if not os.path.isdir(GTZAN_path):\n",
    "    os.mkdir(GTZAN_path)\n",
    "    train_dataset = torchaudio.datasets.GTZAN(root=GTZAN_path, download=True, subset='training')\n",
    "else:\n",
    "    train_dataset = torchaudio.datasets.GTZAN(root=GTZAN_path, subset='training')\n",
    "val_dataset = torchaudio.datasets.GTZAN(root=GTZAN_path, subset='validation')\n",
    "test_dataset = torchaudio.datasets.GTZAN(root=GTZAN_path, subset='testing')\n",
    "\n",
    "# We download the essentia MSD MusiCNN model\n",
    "if not os.path.isfile('msd-musicnn-1.pb'):\n",
    "    !curl -SLO https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.pb\n",
    "\n",
    "class Essentia_MusiCNNMSD_GTZAN_Dataset(Dataset):\n",
    "    \"\"\" The embeddings of the GTZAN dataset extracted with Essentia-Tensorflow's MusiCNN-MSD model. \"\"\"\n",
    "    def __init__(self, GTZAN_dataset, embeddings):\n",
    "        self.GTZAN_dataset = GTZAN_dataset\n",
    "        self.embeddings = embeddings\n",
    "        self.GTZAN_genres = [\n",
    "            \"blues\",\n",
    "            \"classical\",\n",
    "            \"country\",\n",
    "            \"disco\",\n",
    "            \"hiphop\",\n",
    "            \"jazz\",\n",
    "            \"metal\",\n",
    "            \"pop\",\n",
    "            \"reggae\",\n",
    "            \"rock\",\n",
    "        ]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.GTZAN_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        inputs = torch.from_numpy(self.embeddings[idx]).mean(0) #comment mean for original method\n",
    "        labels = torch.tensor(self.GTZAN_genres.index(self.GTZAN_dataset[idx][2]))\n",
    "        \n",
    "        return inputs, labels\n",
    "# We define a shallow model\n",
    "\n",
    "class shallowClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(shallowClassifier, self).__init__()\n",
    "        self.dense1 = nn.Linear(200, 100) #change to 19*200 if commenting .mean()avobe\n",
    "        self.dense2 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1, 200) #change to 200*19 if commenting .mean() above\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build embeddings with GTZAN time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store the embeddings for each subset\n",
    "if not os.path.isfile('train_embeddings.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        train_embeddings.append(es.TensorflowPredictMusiCNN(\n",
    "            graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(resample(track[0].numpy()[0])))\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings.npy',train_embeddings)\n",
    "\n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        val_embeddings.append(es.TensorflowPredictMusiCNN(\n",
    "            graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(resample(track[0].numpy()[0])))\n",
    "    val_embeddings=np.array(val_embeddings)    \n",
    "    np.save('val_embeddings.npy',val_embeddings)\n",
    "\n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        test_embeddings.append(es.TensorflowPredictMusiCNN(\n",
    "            graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(resample(track[0].numpy()[0])))\n",
    "    test_embeddings=np.array(test_embeddings)\n",
    "    np.save('test_embeddings.npy',np.array(test_embeddings))\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings.npy')\n",
    "    val_embeddings=np.load('val_embeddings.npy')\n",
    "    test_embeddings=np.load('test_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding shapes...\n",
    "train_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding types\n",
    "train_embeddings[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embtrain_dataset = Essentia_MusiCNNMSD_GTZAN_Dataset(train_dataset, train_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(train_embeddings, val_embeddings, test_embeddings):\n",
    "    # We compute the distance of the embeddings between all songs in the training set\n",
    "    emb_distance = np.zeros((len(train_embeddings), len(train_embeddings)))\n",
    "\n",
    "    for indxA, trackA in enumerate(train_embeddings):\n",
    "        for indxB, trackB in enumerate(train_embeddings):\n",
    "            emb_distance[indxA, indxB] = np.linalg.norm(trackA - trackB)        \n",
    "\n",
    "    embtrain_dataset = Essentia_MusiCNNMSD_GTZAN_Dataset(train_dataset, train_embeddings)\n",
    "    train_loader = torch.utils.data.DataLoader(embtrain_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "    embval_dataset = Essentia_MusiCNNMSD_GTZAN_Dataset(val_dataset, val_embeddings)\n",
    "    val_loader = torch.utils.data.DataLoader(embval_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    embtest_dataset = Essentia_MusiCNNMSD_GTZAN_Dataset(test_dataset, test_embeddings)\n",
    "    test_loader = torch.utils.data.DataLoader(embtest_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    model = shallowClassifier()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "    num_epochs = 2000\n",
    "    train_losses = torch.zeros(num_epochs)\n",
    "    val_losses = torch.zeros(num_epochs)\n",
    "\n",
    "    bestloss = 100000.0\n",
    "    for epoch in range(num_epochs):\n",
    "        #The train loop\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            # Send data to the GPU\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Clear gradient and forward + loss + backward\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses[epoch] += loss.item()\n",
    "        train_losses[epoch] /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Send data to the GPU\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                outputs = model(inputs) \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_losses[epoch] += loss.item()\n",
    "            val_losses[epoch] /= len(val_loader)\n",
    "            scheduler.step(val_losses[epoch])\n",
    "\n",
    "            # If best epoch, we save parameters\n",
    "            if val_losses[epoch] < bestloss :\n",
    "                bestloss = val_losses[epoch]\n",
    "                torch.save(model.state_dict(), 'model.pth')\n",
    "                \n",
    "        if epoch%100==0:\n",
    "            print('Epoch '+str(epoch)+': Train Loss = '+str(train_losses[epoch].item())+'. Val Loss = '+str(val_losses[epoch].item())+'.')\n",
    "    print('Best validation loss :' + str(bestloss.item()))\n",
    "\n",
    "    # Finally we compute accuracy with the test set\n",
    "    model.load_state_dict(torch.load('model.pth'));\n",
    "    model.eval()\n",
    "    confusion_matrix = torch.zeros(len(embtrain_dataset.GTZAN_genres), len(embtrain_dataset.GTZAN_genres))\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Send data to the GPU\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # Per-class Accuracy\n",
    "    pclass_acc = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
    "    return torch.mean(pclass_acc).item()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GTZAN_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.396742582321167. Val Loss = 2.302741050720215.\n",
      "Epoch 100: Train Loss = 1.0398520231246948. Val Loss = 1.171513557434082.\n",
      "Epoch 200: Train Loss = 0.6912970542907715. Val Loss = 0.885692298412323.\n",
      "Epoch 300: Train Loss = 0.5544649362564087. Val Loss = 0.7747247219085693.\n",
      "Epoch 400: Train Loss = 0.47854354977607727. Val Loss = 0.7215855717658997.\n",
      "Epoch 500: Train Loss = 0.4272844195365906. Val Loss = 0.6938523054122925.\n",
      "Epoch 600: Train Loss = 0.3927702009677887. Val Loss = 0.6783539056777954.\n",
      "Epoch 700: Train Loss = 0.3665103316307068. Val Loss = 0.6705629825592041.\n",
      "Epoch 800: Train Loss = 0.34445664286613464. Val Loss = 0.667378842830658.\n",
      "Epoch 900: Train Loss = 0.3370794653892517. Val Loss = 0.6668924689292908.\n",
      "Epoch 1000: Train Loss = 0.334261029958725. Val Loss = 0.6668926477432251.\n",
      "Epoch 1100: Train Loss = 0.33406737446784973. Val Loss = 0.6668928861618042.\n",
      "Epoch 1200: Train Loss = 0.3340103328227997. Val Loss = 0.6668930053710938.\n",
      "Epoch 1300: Train Loss = 0.33581289649009705. Val Loss = 0.6668932437896729.\n",
      "Epoch 1400: Train Loss = 0.3392503261566162. Val Loss = 0.6668933629989624.\n",
      "Epoch 1500: Train Loss = 0.3355485498905182. Val Loss = 0.6668933629989624.\n",
      "Epoch 1600: Train Loss = 0.3378586173057556. Val Loss = 0.6668936610221863.\n",
      "Epoch 1700: Train Loss = 0.33655914664268494. Val Loss = 0.6668938398361206.\n",
      "Epoch 1800: Train Loss = 0.3341066539287567. Val Loss = 0.6668939590454102.\n",
      "Epoch 1900: Train Loss = 0.3361029624938965. Val Loss = 0.6668940782546997.\n",
      "Best validation loss :0.66688472032547\n"
     ]
    }
   ],
   "source": [
    "baseline = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.49517869949341\n"
     ]
    }
   ],
   "source": [
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline is 80.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = resample(train_dataset[0][0].numpy()[0])\n",
    "original = es.TensorflowPredictMusiCNN(graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspectrogram(audio):\n",
    "    \"\"\"\n",
    "    From a 16kH sample, computes the mel spectrogram with the same signature as done in MelonPlaylist dataset.\n",
    "    \n",
    "    Input:\n",
    "    audio (samples) sampled at 16kHz and between [-1,1]\n",
    "    Output:(frames, 48bands)\n",
    "    \"\"\"    \n",
    "    windowing = es.Windowing(type='hann', normalized=False, zeroPadding=0)\n",
    "    spectrum = es.Spectrum()\n",
    "    melbands = es.MelBands(numberBands=48,\n",
    "                                   sampleRate=16000,\n",
    "                                   lowFrequencyBound=0,\n",
    "                                   highFrequencyBound=16000/2,\n",
    "                                   inputSize=(512+0)//2+1,\n",
    "                                   weighting='linear',\n",
    "                                   normalize='unit_tri',\n",
    "                                   warpingFormula='slaneyMel',\n",
    "                                   type='power')\n",
    "    amp2db = es.UnaryOperator(type='lin2db', scale=2)\n",
    "    result = []\n",
    "    for frame in es.FrameGenerator(audio, frameSize=512, hopSize=256,\n",
    "                                   startFromZero=False):\n",
    "        spectrumFrame = spectrum(windowing(frame))\n",
    "\n",
    "        melFrame = melbands(spectrumFrame)\n",
    "        result.append(amp2db(melFrame))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "melon_sample=melspectrogram(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877, 48)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melon_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled= torch.nn.functional.interpolate(input=torch.from_numpy(melon_sample).unsqueeze(0).unsqueeze(0), size=[melon_sample.shape[0], melon_sample.shape[1]*2], mode='nearest').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1877, 96])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_melonInput_TensorflowPredict(melon_sample, mode):\n",
    "    \"\"\"\n",
    "    Adapts (by treating the spectrogram as an image and using Computer \n",
    "    Vision interpolation methods) the MelonPlaylist mel spectrograms to patches\n",
    "    suitable for using the Essentia-Tensorflow TensorflowPredict algorithm.\n",
    "\n",
    "    Input:\n",
    "    melon_samples (frames, 48bands) dtype=np.float32\n",
    "    mode: 'linear', 'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "    Output:(batch, 187, 1, 96bands)\n",
    "    \"\"\"\n",
    "    db2amp = es.UnaryOperator(type='db2lin', scale=2)\n",
    "    if mode == 'linear':\n",
    "        oversampled = np.zeros((len(melon_sample), melon_sample.shape[1]*2)).astype(np.float32)\n",
    "    else:\n",
    "        renormalized = np.zeros_like(melon_sample).astype(np.float32)\n",
    "    for k in range(len(melon_sample)):\n",
    "        if mode == 'linear':\n",
    "            sample = np.log10(1 + (db2amp(melon_sample[k])*10000))\n",
    "            oversampled[k,:]=np.interp(np.arange(96)/2, np.arange(48), sample)\n",
    "        else:\n",
    "            renormalized[k,:] = np.log10(1 + (db2amp(melon_sample[k])*10000))\n",
    "    if mode != 'linear':\n",
    "        renormalized = torch.from_numpy(renormalized).unsqueeze(0).unsqueeze(0)\n",
    "        if mode == 'trilinear':\n",
    "            oversampled=torch.nn.functional.interpolate(input=renormalized.unsqueeze(0), \n",
    "                                            size=[1,melon_sample.shape[0],melon_sample.shape[1]*2],\n",
    "                                                        mode=mode).squeeze()\n",
    "        else:\n",
    "            oversampled=torch.nn.functional.interpolate(input=renormalized, \n",
    "                                        size=[melon_sample.shape[0],melon_sample.shape[1]*2], \n",
    "                                                        mode=mode).squeeze()\n",
    "        oversampled = oversampled.numpy()\n",
    "    \n",
    "    # Now we cut again, but with hop size of 93 frames as in default TensorflowPredictMusiCNN\n",
    "    new = np.zeros((int(len(oversampled) / 93) - 1, 187, 96)).astype(np.float32)\n",
    "    for k in range(int(len(oversampled) / 93) - 1):\n",
    "        new[k]=oversampled[k*93:k*93+187]\n",
    "    return np.expand_dims(new, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName='msd-musicnn-1.pb'\n",
    "output_layer='model/dense/BiasAdd'\n",
    "input_layer='model/Placeholder'\n",
    "predict = es.TensorflowPredict(graphFilename=modelName,\n",
    "                               inputs=[input_layer],\n",
    "                               outputs=[output_layer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 100 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 400 of 443\n"
     ]
    }
   ],
   "source": [
    "# TensorflowPredictMusiCNN expects mono 16kHz sample rate inputs. Resample needed\n",
    "# Compute and store the embeddings for each subset\n",
    "if not os.path.isfile('train_embeddings_linear.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='linear'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_linear.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='linear'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_linear.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='linear'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_linear.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_linear.npy')\n",
    "    val_embeddings=np.load('val_embeddings_linear.npy')\n",
    "    test_embeddings=np.load('test_embeddings_linear.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding shapes...\n",
    "train_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding types\n",
    "train_embeddings[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-train, now with interpolated melspecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.3252789974212646. Val Loss = 2.2550265789031982.\n",
      "Epoch 100: Train Loss = 1.4404184818267822. Val Loss = 1.5836281776428223.\n",
      "Epoch 200: Train Loss = 1.0612469911575317. Val Loss = 1.2955150604248047.\n",
      "Epoch 300: Train Loss = 0.8743215799331665. Val Loss = 1.1578919887542725.\n",
      "Epoch 400: Train Loss = 0.7598857879638672. Val Loss = 1.0832873582839966.\n",
      "Epoch 500: Train Loss = 0.6838250756263733. Val Loss = 1.0374938249588013.\n",
      "Epoch 600: Train Loss = 0.6335861086845398. Val Loss = 1.0076253414154053.\n",
      "Epoch 700: Train Loss = 0.5872496962547302. Val Loss = 0.9864686131477356.\n",
      "Epoch 800: Train Loss = 0.5609604120254517. Val Loss = 0.9710853099822998.\n",
      "Epoch 900: Train Loss = 0.535830020904541. Val Loss = 0.9588419198989868.\n",
      "Epoch 1000: Train Loss = 0.5032868385314941. Val Loss = 0.9489818215370178.\n",
      "Epoch 1100: Train Loss = 0.4847221374511719. Val Loss = 0.9403696656227112.\n",
      "Epoch 1200: Train Loss = 0.46988943219184875. Val Loss = 0.9338710308074951.\n",
      "Epoch 1300: Train Loss = 0.45106011629104614. Val Loss = 0.9278390407562256.\n",
      "Epoch 1400: Train Loss = 0.4404187500476837. Val Loss = 0.9228757619857788.\n",
      "Epoch 1500: Train Loss = 0.4254719913005829. Val Loss = 0.918872594833374.\n",
      "Epoch 1600: Train Loss = 0.4217528998851776. Val Loss = 0.9179247617721558.\n",
      "Epoch 1700: Train Loss = 0.4230216443538666. Val Loss = 0.9179247617721558.\n",
      "Epoch 1800: Train Loss = 0.4195776581764221. Val Loss = 0.9179248213768005.\n",
      "Epoch 1900: Train Loss = 0.41861554980278015. Val Loss = 0.9179250001907349.\n",
      "Best validation loss :0.9179226160049438\n"
     ]
    }
   ],
   "source": [
    "interpolated = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.57183599472046\n"
     ]
    }
   ],
   "source": [
    "print(interpolated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with random embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.32436203956604. Val Loss = 2.3439722061157227.\n",
      "Epoch 100: Train Loss = 2.2854135036468506. Val Loss = 2.339341402053833.\n",
      "Epoch 200: Train Loss = 2.2608494758605957. Val Loss = 2.3376495838165283.\n",
      "Epoch 300: Train Loss = 2.25998854637146. Val Loss = 2.337649345397949.\n",
      "Epoch 400: Train Loss = 2.2603085041046143. Val Loss = 2.337649345397949.\n",
      "Epoch 500: Train Loss = 2.260315179824829. Val Loss = 2.3376495838165283.\n",
      "Epoch 600: Train Loss = 2.2611031532287598. Val Loss = 2.3376495838165283.\n",
      "Epoch 700: Train Loss = 2.26021146774292. Val Loss = 2.337649345397949.\n",
      "Epoch 800: Train Loss = 2.2611281871795654. Val Loss = 2.3376495838165283.\n",
      "Epoch 900: Train Loss = 2.25942063331604. Val Loss = 2.33764910697937.\n",
      "Epoch 1000: Train Loss = 2.260310173034668. Val Loss = 2.33764910697937.\n",
      "Epoch 1100: Train Loss = 2.259648084640503. Val Loss = 2.337649345397949.\n",
      "Epoch 1200: Train Loss = 2.2606582641601562. Val Loss = 2.33764910697937.\n",
      "Epoch 1300: Train Loss = 2.258835554122925. Val Loss = 2.33764910697937.\n",
      "Epoch 1400: Train Loss = 2.260551929473877. Val Loss = 2.33764910697937.\n",
      "Epoch 1500: Train Loss = 2.259047508239746. Val Loss = 2.337648868560791.\n",
      "Epoch 1600: Train Loss = 2.261046886444092. Val Loss = 2.33764910697937.\n",
      "Epoch 1700: Train Loss = 2.260843276977539. Val Loss = 2.33764910697937.\n",
      "Epoch 1800: Train Loss = 2.2607481479644775. Val Loss = 2.33764910697937.\n",
      "Epoch 1900: Train Loss = 2.2605855464935303. Val Loss = 2.337648868560791.\n",
      "Best validation loss :2.337648630142212\n"
     ]
    }
   ],
   "source": [
    "rand = train_test(np.reshape(5*np.random.randn(train_embeddings.size).astype(np.float32), train_embeddings.shape), \n",
    "                 np.reshape(5*np.random.randn(val_embeddings.size).astype(np.float32), val_embeddings.shape), \n",
    "                 np.reshape(5*np.random.randn(test_embeddings.size).astype(np.float32), test_embeddings.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.379075467586517\n"
     ]
    }
   ],
   "source": [
    "print(rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with random musiCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_V(nn.Module):\n",
    "    # vertical convolution\n",
    "    def __init__(self, input_channels, output_channels, filter_shape):\n",
    "        super(Conv_V, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, filter_shape,\n",
    "                              padding=(0, filter_shape[1]//2))\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        freq = x.size(2)\n",
    "        out = nn.MaxPool2d((freq, 1), stride=(freq, 1))(x)\n",
    "        out = out.squeeze(2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Conv_H(nn.Module):\n",
    "    # horizontal convolution\n",
    "    def __init__(self, input_channels, output_channels, filter_length):\n",
    "        super(Conv_H, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_channels, output_channels, filter_length,\n",
    "                              padding=filter_length//2)\n",
    "        self.bn = nn.BatchNorm1d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        freq = x.size(2)\n",
    "        out = nn.AvgPool2d((freq, 1), stride=(freq, 1))(x)\n",
    "        out = out.squeeze(2)\n",
    "        out = self.relu(self.bn(self.conv(out)))\n",
    "        return out\n",
    "\n",
    "class Conv_1d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, shape=3, stride=1, pooling=2):\n",
    "        super(Conv_1d, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_channels, output_channels, shape, stride=stride, padding=shape//2)\n",
    "        self.bn = nn.BatchNorm1d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mp = nn.MaxPool1d(pooling)\n",
    "    def forward(self, x):\n",
    "        out = self.mp(self.relu(self.bn(self.conv(x))))\n",
    "        return out\n",
    "    \n",
    "class Musicnn(nn.Module):\n",
    "    '''\n",
    "    Pons et al. 2017\n",
    "    End-to-end learning for music audio tagging at scale.\n",
    "    This is the updated implementation of the original paper. Referred to the Musicnn code.\n",
    "    https://github.com/jordipons/musicnn\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                sample_rate=16000,\n",
    "                n_fft=512,\n",
    "                f_min=0.0,\n",
    "                f_max=8000.0,\n",
    "                n_mels=96,\n",
    "                n_class=50,\n",
    "                dataset='mtat'):\n",
    "        super(Musicnn, self).__init__()\n",
    "\n",
    "        # Spectrogram\n",
    "        self.spec = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate,\n",
    "                                                         n_fft=n_fft,\n",
    "                                                         f_min=f_min,\n",
    "                                                         f_max=f_max,\n",
    "                                                         n_mels=n_mels)\n",
    "        self.to_db = torchaudio.transforms.AmplitudeToDB()\n",
    "        self.spec_bn = nn.BatchNorm2d(1)\n",
    "\n",
    "        # Pons front-end\n",
    "        m1 = Conv_V(1, 204, (int(0.7*96), 7))\n",
    "        m2 = Conv_V(1, 204, (int(0.4*96), 7))\n",
    "        m3 = Conv_H(1, 51, 129)\n",
    "        m4 = Conv_H(1, 51, 65)\n",
    "        m5 = Conv_H(1, 51, 33)\n",
    "        self.layers = nn.ModuleList([m1, m2, m3, m4, m5])\n",
    "\n",
    "        # Pons back-end\n",
    "        backend_channel= 512 if dataset=='msd' else 64\n",
    "        self.layer1 = Conv_1d(561, backend_channel, 7, 1, 1)\n",
    "        self.layer2 = Conv_1d(backend_channel, backend_channel, 7, 1, 1)\n",
    "        self.layer3 = Conv_1d(backend_channel, backend_channel, 7, 1, 1)\n",
    "\n",
    "        # Dense\n",
    "        dense_channel = 500 if dataset=='msd' else 200\n",
    "        self.dense1 = nn.Linear((561+(backend_channel*3))*2, dense_channel)\n",
    "        self.bn = nn.BatchNorm1d(dense_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(dense_channel, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Spectrogram\n",
    "        x = self.spec(x)\n",
    "        x = self.to_db(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.spec_bn(x)\n",
    "\n",
    "        # Pons front-end\n",
    "        out = []\n",
    "        for layer in self.layers:\n",
    "            out.append(layer(x))\n",
    "        out = torch.cat(out, dim=1)\n",
    "\n",
    "        # Pons back-end\n",
    "        length = out.size(2)\n",
    "        res1 = self.layer1(out)\n",
    "        res2 = self.layer2(res1) + res1\n",
    "        res3 = self.layer3(res2) + res2\n",
    "        out = torch.cat([out, res1, res2, res3], 1)\n",
    "\n",
    "        mp = nn.MaxPool1d(length)(out)\n",
    "        avgp = nn.AvgPool1d(length)(out)\n",
    "        out = torch.cat([mp, avgp], dim=1)\n",
    "        out = out.squeeze(2)\n",
    "\n",
    "        out = self.relu(self.bn(self.dense1(out)))\n",
    "        out = self.dropout(out)\n",
    "        #out = self.dense2(out)\n",
    "        #out = nn.Sigmoid()(out)\n",
    "\n",
    "        return out\n",
    "rand_musiCNN = Musicnn()\n",
    "rand_musiCNN.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store the embeddings for each subset\n",
    "if not os.path.isfile('train_embeddings_random.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        train_embeddings.append(rand_musiCNN(torch.from_numpy(resample(track[0].numpy()[0])).unsqueeze(0)).detach().numpy())\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_random.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        val_embeddings.append(rand_musiCNN(torch.from_numpy(resample(track[0].numpy()[0])).unsqueeze(0)).detach().numpy())\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_random.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        test_embeddings.append(rand_musiCNN(torch.from_numpy(resample(track[0].numpy()[0])).unsqueeze(0)).detach().numpy())\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_random.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_random.npy')\n",
    "    val_embeddings=np.load('val_embeddings_random.npy')\n",
    "    test_embeddings=np.load('test_embeddings_random.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 3.1070022583007812. Val Loss = 2.6462361812591553.\n",
      "Epoch 100: Train Loss = 1.8885945081710815. Val Loss = 2.019928216934204.\n",
      "Epoch 200: Train Loss = 1.7573341131210327. Val Loss = 1.966556429862976.\n",
      "Epoch 300: Train Loss = 1.6742095947265625. Val Loss = 1.937293291091919.\n",
      "Epoch 400: Train Loss = 1.6005276441574097. Val Loss = 1.910744547843933.\n",
      "Epoch 500: Train Loss = 1.5343894958496094. Val Loss = 1.8919563293457031.\n",
      "Epoch 600: Train Loss = 1.506278157234192. Val Loss = 1.8848636150360107.\n",
      "Epoch 700: Train Loss = 1.5050195455551147. Val Loss = 1.8848612308502197.\n",
      "Epoch 800: Train Loss = 1.5083385705947876. Val Loss = 1.8848590850830078.\n",
      "Epoch 900: Train Loss = 1.5047283172607422. Val Loss = 1.88485586643219.\n",
      "Epoch 1000: Train Loss = 1.5083122253417969. Val Loss = 1.8848528861999512.\n",
      "Epoch 1100: Train Loss = 1.505696415901184. Val Loss = 1.884851336479187.\n",
      "Epoch 1200: Train Loss = 1.5050700902938843. Val Loss = 1.8848495483398438.\n",
      "Epoch 1300: Train Loss = 1.5130641460418701. Val Loss = 1.884846568107605.\n",
      "Epoch 1400: Train Loss = 1.510337471961975. Val Loss = 1.8848445415496826.\n",
      "Epoch 1500: Train Loss = 1.5111230611801147. Val Loss = 1.8848412036895752.\n",
      "Epoch 1600: Train Loss = 1.5096279382705688. Val Loss = 1.8848392963409424.\n",
      "Epoch 1700: Train Loss = 1.5088311433792114. Val Loss = 1.8848379850387573.\n",
      "Epoch 1800: Train Loss = 1.5050125122070312. Val Loss = 1.8848367929458618.\n",
      "Epoch 1900: Train Loss = 1.5085166692733765. Val Loss = 1.8848350048065186.\n",
      "Best validation loss :1.884297251701355\n"
     ]
    }
   ],
   "source": [
    "random_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.58379530906677"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We repeat but with image reshaping (torch) methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 100 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 400 of 443\n"
     ]
    }
   ],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_nearest.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='nearest'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_nearest.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='nearest'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_nearest.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='nearest'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_nearest.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_nearest.npy')\n",
    "    val_embeddings=np.load('val_embeddings_nearest.npy')\n",
    "    test_embeddings=np.load('test_embeddings_nearest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.481893301010132. Val Loss = 2.4405312538146973.\n",
      "Epoch 100: Train Loss = 1.4496593475341797. Val Loss = 1.5998427867889404.\n",
      "Epoch 200: Train Loss = 1.099965214729309. Val Loss = 1.320712924003601.\n",
      "Epoch 300: Train Loss = 0.9284553527832031. Val Loss = 1.1870777606964111.\n",
      "Epoch 400: Train Loss = 0.824478268623352. Val Loss = 1.105027675628662.\n",
      "Epoch 500: Train Loss = 0.7539178133010864. Val Loss = 1.0494338274002075.\n",
      "Epoch 600: Train Loss = 0.7045766115188599. Val Loss = 1.0080229043960571.\n",
      "Epoch 700: Train Loss = 0.6616665124893188. Val Loss = 0.9768028259277344.\n",
      "Epoch 800: Train Loss = 0.6306905746459961. Val Loss = 0.9525780081748962.\n",
      "Epoch 900: Train Loss = 0.5976877212524414. Val Loss = 0.9338906407356262.\n",
      "Epoch 1000: Train Loss = 0.5823160409927368. Val Loss = 0.9181756973266602.\n",
      "Epoch 1100: Train Loss = 0.552892804145813. Val Loss = 0.9049414396286011.\n",
      "Epoch 1200: Train Loss = 0.5392934679985046. Val Loss = 0.8934511542320251.\n",
      "Epoch 1300: Train Loss = 0.5251263976097107. Val Loss = 0.8838518857955933.\n",
      "Epoch 1400: Train Loss = 0.50965815782547. Val Loss = 0.875886857509613.\n",
      "Epoch 1500: Train Loss = 0.5003290176391602. Val Loss = 0.8692814111709595.\n",
      "Epoch 1600: Train Loss = 0.49186769127845764. Val Loss = 0.868654191493988.\n",
      "Epoch 1700: Train Loss = 0.4937593638896942. Val Loss = 0.8686535954475403.\n",
      "Epoch 1800: Train Loss = 0.4971160888671875. Val Loss = 0.8686524629592896.\n",
      "Epoch 1900: Train Loss = 0.4954307973384857. Val Loss = 0.868651807308197.\n",
      "Best validation loss :0.8686508536338806\n"
     ]
    }
   ],
   "source": [
    "nearest_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.28104591369629"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enricguso/venvs/melon_venv/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 100 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 400 of 443\n"
     ]
    }
   ],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_bilinear.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='bilinear'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_bilinear.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='bilinear'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_bilinear.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='bilinear'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_bilinear.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_bilinear.npy')\n",
    "    val_embeddings=np.load('val_embeddings_bilinear.npy')\n",
    "    test_embeddings=np.load('test_embeddings_bilinear.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.740442991256714. Val Loss = 2.613727569580078.\n",
      "Epoch 100: Train Loss = 1.6834008693695068. Val Loss = 1.8165361881256104.\n",
      "Epoch 200: Train Loss = 1.3514814376831055. Val Loss = 1.5413243770599365.\n",
      "Epoch 300: Train Loss = 1.145402193069458. Val Loss = 1.38668954372406.\n",
      "Epoch 400: Train Loss = 1.0153820514678955. Val Loss = 1.2937651872634888.\n",
      "Epoch 500: Train Loss = 0.921638548374176. Val Loss = 1.23270583152771.\n",
      "Epoch 600: Train Loss = 0.8532682061195374. Val Loss = 1.1908600330352783.\n",
      "Epoch 700: Train Loss = 0.7976685166358948. Val Loss = 1.1608574390411377.\n",
      "Epoch 800: Train Loss = 0.7582550048828125. Val Loss = 1.1391427516937256.\n",
      "Epoch 900: Train Loss = 0.7223774194717407. Val Loss = 1.1221624612808228.\n",
      "Epoch 1000: Train Loss = 0.6852974891662598. Val Loss = 1.1098588705062866.\n",
      "Epoch 1100: Train Loss = 0.662321150302887. Val Loss = 1.0993478298187256.\n",
      "Epoch 1200: Train Loss = 0.6405248641967773. Val Loss = 1.0926884412765503.\n",
      "Epoch 1300: Train Loss = 0.6404222846031189. Val Loss = 1.0926878452301025.\n",
      "Epoch 1400: Train Loss = 0.6414442658424377. Val Loss = 1.0926861763000488.\n",
      "Epoch 1500: Train Loss = 0.6398891806602478. Val Loss = 1.0926845073699951.\n",
      "Epoch 1600: Train Loss = 0.6396841406822205. Val Loss = 1.0926826000213623.\n",
      "Epoch 1700: Train Loss = 0.6394678950309753. Val Loss = 1.09268057346344.\n",
      "Epoch 1800: Train Loss = 0.645650327205658. Val Loss = 1.0926789045333862.\n",
      "Epoch 1900: Train Loss = 0.6411604881286621. Val Loss = 1.0926778316497803.\n",
      "Best validation loss :1.092676043510437\n"
     ]
    }
   ],
   "source": [
    "bilinear_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.29597854614258"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilinear_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enricguso/venvs/melon_venv/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 100 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 400 of 443\n"
     ]
    }
   ],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_bicubic.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='bicubic'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_bicubic.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='bicubic'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_bicubic.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='bicubic'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_bicubic.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_bicubic.npy')\n",
    "    val_embeddings=np.load('val_embeddings_bicubic.npy')\n",
    "    test_embeddings=np.load('test_embeddings_bicubic.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.4317805767059326. Val Loss = 2.4642066955566406.\n",
      "Epoch 100: Train Loss = 1.5333970785140991. Val Loss = 1.6570769548416138.\n",
      "Epoch 200: Train Loss = 1.162260890007019. Val Loss = 1.3547444343566895.\n",
      "Epoch 300: Train Loss = 0.9632114171981812. Val Loss = 1.2005283832550049.\n",
      "Epoch 400: Train Loss = 0.8469470143318176. Val Loss = 1.114084005355835.\n",
      "Epoch 500: Train Loss = 0.7700648307800293. Val Loss = 1.0595790147781372.\n",
      "Epoch 600: Train Loss = 0.7038282752037048. Val Loss = 1.0229744911193848.\n",
      "Epoch 700: Train Loss = 0.6673607230186462. Val Loss = 0.99671870470047.\n",
      "Epoch 800: Train Loss = 0.629788875579834. Val Loss = 0.9775038957595825.\n",
      "Epoch 900: Train Loss = 0.5979045033454895. Val Loss = 0.9635715484619141.\n",
      "Epoch 1000: Train Loss = 0.5765382647514343. Val Loss = 0.9528799653053284.\n",
      "Epoch 1100: Train Loss = 0.5535461902618408. Val Loss = 0.9432661533355713.\n",
      "Epoch 1200: Train Loss = 0.5331271886825562. Val Loss = 0.9378153085708618.\n",
      "Epoch 1300: Train Loss = 0.5364290475845337. Val Loss = 0.9377944469451904.\n",
      "Epoch 1400: Train Loss = 0.5376008152961731. Val Loss = 0.9377938508987427.\n",
      "Epoch 1500: Train Loss = 0.5329108834266663. Val Loss = 0.9377927184104919.\n",
      "Epoch 1600: Train Loss = 0.5331939458847046. Val Loss = 0.9377918243408203.\n",
      "Epoch 1700: Train Loss = 0.5340070128440857. Val Loss = 0.9377909898757935.\n",
      "Epoch 1800: Train Loss = 0.5372022986412048. Val Loss = 0.9377902150154114.\n",
      "Epoch 1900: Train Loss = 0.5362211465835571. Val Loss = 0.9377893805503845.\n",
      "Best validation loss :0.9377885460853577\n"
     ]
    }
   ],
   "source": [
    "bicubic_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.82840013504028"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bicubic_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 100 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 400 of 443\n"
     ]
    }
   ],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_area.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='area'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_area.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='area'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_area.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='area'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_area.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_area.npy')\n",
    "    val_embeddings=np.load('val_embeddings_area.npy')\n",
    "    test_embeddings=np.load('test_embeddings_area.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.5877630710601807. Val Loss = 2.5556771755218506.\n",
      "Epoch 100: Train Loss = 1.540202260017395. Val Loss = 1.6914875507354736.\n",
      "Epoch 200: Train Loss = 1.1952879428863525. Val Loss = 1.4031914472579956.\n",
      "Epoch 300: Train Loss = 1.0138425827026367. Val Loss = 1.2572230100631714.\n",
      "Epoch 400: Train Loss = 0.9012598991394043. Val Loss = 1.1692289113998413.\n",
      "Epoch 500: Train Loss = 0.8224290609359741. Val Loss = 1.111919641494751.\n",
      "Epoch 600: Train Loss = 0.7670912742614746. Val Loss = 1.071157455444336.\n",
      "Epoch 700: Train Loss = 0.7237657308578491. Val Loss = 1.0406895875930786.\n",
      "Epoch 800: Train Loss = 0.6879711151123047. Val Loss = 1.017800211906433.\n",
      "Epoch 900: Train Loss = 0.6537861824035645. Val Loss = 0.9994897842407227.\n",
      "Epoch 1000: Train Loss = 0.6328492164611816. Val Loss = 0.9851677417755127.\n",
      "Epoch 1100: Train Loss = 0.6084261536598206. Val Loss = 0.974022626876831.\n",
      "Epoch 1200: Train Loss = 0.5936712622642517. Val Loss = 0.9675305485725403.\n",
      "Epoch 1300: Train Loss = 0.5975690484046936. Val Loss = 0.967518150806427.\n",
      "Epoch 1400: Train Loss = 0.5954475998878479. Val Loss = 0.9675160050392151.\n",
      "Epoch 1500: Train Loss = 0.5952368974685669. Val Loss = 0.96751469373703.\n",
      "Epoch 1600: Train Loss = 0.5971670150756836. Val Loss = 0.9675129652023315.\n",
      "Epoch 1700: Train Loss = 0.5970282554626465. Val Loss = 0.9675108194351196.\n",
      "Epoch 1800: Train Loss = 0.5951768159866333. Val Loss = 0.967508852481842.\n",
      "Epoch 1900: Train Loss = 0.5995302200317383. Val Loss = 0.967507004737854.\n",
      "Best validation loss :0.9675048589706421\n"
     ]
    }
   ],
   "source": [
    "area_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.03759264945984"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enricguso/venvs/melon_venv/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 100 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 400 of 443\n"
     ]
    }
   ],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_trilinear.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='trilinear'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_trilinear.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='trilinear'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_trilinear.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict(melspectrogram(resample(track[0].numpy()[0])),mode='trilinear'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_trilinear.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_trilinear.npy')\n",
    "    val_embeddings=np.load('val_embeddings_trilinear.npy')\n",
    "    test_embeddings=np.load('test_embeddings_trilinear.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.307088851928711. Val Loss = 2.2478086948394775.\n",
      "Epoch 100: Train Loss = 1.5482195615768433. Val Loss = 1.6184629201889038.\n",
      "Epoch 200: Train Loss = 1.2306087017059326. Val Loss = 1.381377100944519.\n",
      "Epoch 300: Train Loss = 1.05232572555542. Val Loss = 1.259857416152954.\n",
      "Epoch 400: Train Loss = 0.943603515625. Val Loss = 1.187566876411438.\n",
      "Epoch 500: Train Loss = 0.8589625358581543. Val Loss = 1.1405445337295532.\n",
      "Epoch 600: Train Loss = 0.7986156344413757. Val Loss = 1.106937050819397.\n",
      "Epoch 700: Train Loss = 0.754830539226532. Val Loss = 1.0840868949890137.\n",
      "Epoch 800: Train Loss = 0.7156203985214233. Val Loss = 1.0678960084915161.\n",
      "Epoch 900: Train Loss = 0.681488573551178. Val Loss = 1.0560524463653564.\n",
      "Epoch 1000: Train Loss = 0.652154266834259. Val Loss = 1.046676516532898.\n",
      "Epoch 1100: Train Loss = 0.6399688124656677. Val Loss = 1.0439099073410034.\n",
      "Epoch 1200: Train Loss = 0.6442651152610779. Val Loss = 1.043907642364502.\n",
      "Epoch 1300: Train Loss = 0.6395034193992615. Val Loss = 1.0439051389694214.\n",
      "Epoch 1400: Train Loss = 0.6374525427818298. Val Loss = 1.0439022779464722.\n",
      "Epoch 1500: Train Loss = 0.6388558149337769. Val Loss = 1.0439001321792603.\n",
      "Epoch 1600: Train Loss = 0.6396313309669495. Val Loss = 1.0438976287841797.\n",
      "Epoch 1700: Train Loss = 0.6392511129379272. Val Loss = 1.04389488697052.\n",
      "Epoch 1800: Train Loss = 0.6442704200744629. Val Loss = 1.0438917875289917.\n",
      "Epoch 1900: Train Loss = 0.6416539549827576. Val Loss = 1.0438896417617798.\n",
      "Best validation loss :1.0436123609542847\n"
     ]
    }
   ],
   "source": [
    "trilinear_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.40250897407532"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trilinear_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now sonifying (inverting the Mel spectograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store the embeddings for each subset\n",
    "if not os.path.isfile('train_embeddings_sonify.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        #We de-normalize the melonstuff\n",
    "        ess=melspectrogram(resample(track[0].numpy()[0]))\n",
    "        db2amp = es.UnaryOperator(type='db2lin', scale=2)\n",
    "        for k in range(len(ess)):\n",
    "            ess[k] = db2amp(ess[k])\n",
    "        sonified = librosa.feature.inverse.mel_to_audio(M=ess.T, sr=16000, n_fft=512, hop_length=256, center=True, norm='slaney', htk=False)\n",
    "        train_embeddings.append(es.TensorflowPredictMusiCNN(\n",
    "            graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(sonified))\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_sonify.npy',train_embeddings)\n",
    "    i=0\n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        i+=1\n",
    "        print('Processing track '+str(i)+' of '+str(len(val_dataset)))\n",
    "        #We de-normalize the melonstuff\n",
    "        ess=melspectrogram(resample(track[0].numpy()[0]))\n",
    "        db2amp = es.UnaryOperator(type='db2lin', scale=2)\n",
    "        for k in range(len(ess)):\n",
    "            ess[k] = db2amp(ess[k])\n",
    "        sonified = librosa.feature.inverse.mel_to_audio(M=ess.T, sr=16000, n_fft=512, hop_length=256, center=True, norm='slaney', htk=False)\n",
    "        val_embeddings.append(es.TensorflowPredictMusiCNN(\n",
    "            graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(sonified))\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_sonify.npy',train_embeddings)\n",
    "    i=0                                \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        i+=1\n",
    "        print('Processing track '+str(i)+' of '+str(len(test_dataset)))\n",
    "        #We de-normalize the melonstuff\n",
    "        ess=melspectrogram(resample(track[0].numpy()[0]))\n",
    "        db2amp = es.UnaryOperator(type='db2lin', scale=2)\n",
    "        for k in range(len(ess)):\n",
    "            ess[k] = db2amp(ess[k])\n",
    "        sonified = librosa.feature.inverse.mel_to_audio(M=ess.T, sr=16000, n_fft=512, hop_length=256, center=True, norm='slaney', htk=False)\n",
    "        test_embeddings.append(es.TensorflowPredictMusiCNN(\n",
    "            graphFilename='msd-musicnn-1.pb', output='model/dense/BiasAdd')(sonified))\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_sonify.npy',test_embeddings)\n",
    "\n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_sonify.npy')\n",
    "    val_embeddings=np.load('val_embeddings_sonify.npy')\n",
    "    test_embeddings=np.load('test_embeddings_sonify.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.4772136211395264. Val Loss = 2.598193883895874.\n",
      "Epoch 100: Train Loss = 1.9324365854263306. Val Loss = 2.5817947387695312.\n",
      "Epoch 200: Train Loss = 1.9332129955291748. Val Loss = 2.5817973613739014.\n",
      "Epoch 300: Train Loss = 1.932881236076355. Val Loss = 2.5817999839782715.\n",
      "Epoch 400: Train Loss = 1.9336708784103394. Val Loss = 2.581803321838379.\n",
      "Epoch 500: Train Loss = 1.9348188638687134. Val Loss = 2.581805944442749.\n",
      "Epoch 600: Train Loss = 1.9329769611358643. Val Loss = 2.5818088054656982.\n",
      "Epoch 700: Train Loss = 1.9353917837142944. Val Loss = 2.5818114280700684.\n",
      "Epoch 800: Train Loss = 1.934230089187622. Val Loss = 2.5818142890930176.\n",
      "Epoch 900: Train Loss = 1.9341288805007935. Val Loss = 2.581817150115967.\n",
      "Epoch 1000: Train Loss = 1.9353611469268799. Val Loss = 2.581820011138916.\n",
      "Epoch 1100: Train Loss = 1.9351215362548828. Val Loss = 2.5818228721618652.\n",
      "Epoch 1200: Train Loss = 1.9320887327194214. Val Loss = 2.5818252563476562.\n",
      "Epoch 1300: Train Loss = 1.9326187372207642. Val Loss = 2.5818281173706055.\n",
      "Epoch 1400: Train Loss = 1.9317518472671509. Val Loss = 2.581831216812134.\n",
      "Epoch 1500: Train Loss = 1.9345680475234985. Val Loss = 2.581834077835083.\n",
      "Epoch 1600: Train Loss = 1.9343658685684204. Val Loss = 2.5818369388580322.\n",
      "Epoch 1700: Train Loss = 1.9357455968856812. Val Loss = 2.5818400382995605.\n",
      "Epoch 1800: Train Loss = 1.9299986362457275. Val Loss = 2.5818426609039307.\n",
      "Epoch 1900: Train Loss = 1.9322230815887451. Val Loss = 2.58184552192688.\n",
      "Best validation loss :2.5755696296691895\n"
     ]
    }
   ],
   "source": [
    "sonify_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.74985694885254"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonify_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat BILINEAR but with align-corners True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_melonInput_TensorflowPredict_aligned(melon_sample, mode):\n",
    "    \"\"\"\n",
    "    Adapts (by treating the spectrogram as an image and using Computer \n",
    "    Vision interpolation methods) the MelonPlaylist mel spectrograms to patches\n",
    "    suitable for using the Essentia-Tensorflow TensorflowPredict algorithm.\n",
    "\n",
    "    Input:\n",
    "    melon_samples (frames, 48bands)\n",
    "    mode: 'linear', 'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "    Output:(batch, 187, 1, 96bands)\n",
    "    \"\"\"\n",
    "    db2amp = es.UnaryOperator(type='db2lin', scale=2)\n",
    "    if mode == 'linear':\n",
    "        oversampled = np.zeros((len(melon_sample), melon_sample.shape[1]*2)).astype(np.float32)\n",
    "    else:\n",
    "        renormalized = np.zeros_like(melon_sample).astype(np.float32)\n",
    "    for k in range(len(melon_sample)):\n",
    "        if mode == 'linear':\n",
    "            sample = np.log10(1 + (db2amp(melon_sample[k])*10000))\n",
    "            oversampled[k,:]=np.interp(np.arange(96)/2, np.arange(48), sample)\n",
    "        else:\n",
    "            renormalized[k,:] = np.log10(1 + (db2amp(melon_sample[k])*10000))\n",
    "    if mode != 'linear':\n",
    "        renormalized = torch.from_numpy(renormalized).unsqueeze(0).unsqueeze(0)\n",
    "        if mode == 'trilinear':\n",
    "            oversampled=torch.nn.functional.interpolate(input=renormalized.unsqueeze(0), \n",
    "                                            size=[1,melon_sample.shape[0],melon_sample.shape[1]*2], \n",
    "                                                        mode=mode).squeeze()\n",
    "        else:\n",
    "            oversampled=torch.nn.functional.interpolate(input=renormalized, \n",
    "                                        size=[melon_sample.shape[0],melon_sample.shape[1]*2], \n",
    "                                                        mode=mode, align_corners=True).squeeze()\n",
    "        oversampled = oversampled.numpy()\n",
    "    \n",
    "    # Now we cut again, but with hop size of 93 frames as in default TensorflowPredictMusiCNN\n",
    "    new = np.zeros((int(len(oversampled) / 93) - 1, 187, 96)).astype(np.float32)\n",
    "    for k in range(int(len(oversampled) / 93) - 1):\n",
    "        new[k]=oversampled[k*93:k*93+187]\n",
    "    return np.expand_dims(new, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_bicubic_aligned.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        if i%100==0:\n",
    "            print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict_aligned(melspectrogram(resample(track[0].numpy()[0])),mode='bicubic'))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_bicubic_aligned.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict_aligned(melspectrogram(resample(track[0].numpy()[0])),mode='bicubic'))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_bicubic_aligned.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict_aligned(melspectrogram(resample(track[0].numpy()[0])),mode='bicubic'))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_bicubic_aligned.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_bicubic_aligned.npy')\n",
    "    val_embeddings=np.load('val_embeddings_bicubic_aligned.npy')\n",
    "    test_embeddings=np.load('test_embeddings_bicubic_aligned.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.3671836853027344. Val Loss = 2.415376901626587.\n",
      "Epoch 100: Train Loss = 1.4830845594406128. Val Loss = 1.652207851409912.\n",
      "Epoch 200: Train Loss = 1.1473748683929443. Val Loss = 1.3631185293197632.\n",
      "Epoch 300: Train Loss = 0.9641218185424805. Val Loss = 1.2145800590515137.\n",
      "Epoch 400: Train Loss = 0.8493464589118958. Val Loss = 1.1284267902374268.\n",
      "Epoch 500: Train Loss = 0.7706289887428284. Val Loss = 1.0719891786575317.\n",
      "Epoch 600: Train Loss = 0.711894690990448. Val Loss = 1.0329068899154663.\n",
      "Epoch 700: Train Loss = 0.6667733788490295. Val Loss = 1.0051604509353638.\n",
      "Epoch 800: Train Loss = 0.6325655579566956. Val Loss = 0.9841317534446716.\n",
      "Epoch 900: Train Loss = 0.6035242676734924. Val Loss = 0.9692971706390381.\n",
      "Epoch 1000: Train Loss = 0.5758257508277893. Val Loss = 0.9578670263290405.\n",
      "Epoch 1100: Train Loss = 0.5529043078422546. Val Loss = 0.947456955909729.\n",
      "Epoch 1200: Train Loss = 0.5486071705818176. Val Loss = 0.9470803141593933.\n",
      "Epoch 1300: Train Loss = 0.5525979399681091. Val Loss = 0.9470786452293396.\n",
      "Epoch 1400: Train Loss = 0.5567907691001892. Val Loss = 0.9470774531364441.\n",
      "Epoch 1500: Train Loss = 0.550570547580719. Val Loss = 0.9470764994621277.\n",
      "Epoch 1600: Train Loss = 0.5519466996192932. Val Loss = 0.9470750093460083.\n",
      "Epoch 1700: Train Loss = 0.5519702434539795. Val Loss = 0.9470740556716919.\n",
      "Epoch 1800: Train Loss = 0.5513712167739868. Val Loss = 0.9470729827880859.\n",
      "Epoch 1900: Train Loss = 0.5569378137588501. Val Loss = 0.9470722675323486.\n",
      "Best validation loss :0.9470709562301636\n"
     ]
    }
   ],
   "source": [
    "bicubic_aligned_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.23251271247864"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bicubic_aligned_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try going back to STFT, then to new mel with librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_melonInput_TensorflowPredict_STFT(ess):\n",
    "    \"\"\"\n",
    "    Adapts (by treating the spectrogram as an image and using Computer \n",
    "    Vision interpolation methods) the MelonPlaylist mel spectrograms to patches\n",
    "    suitable for using the Essentia-Tensorflow TensorflowPredict algorithm.\n",
    "\n",
    "    Input:\n",
    "    melon_samples (frames, 48bands)\n",
    "    mode: 'linear', 'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "    Output:(batch, 187, 1, 96bands)\n",
    "    \"\"\"\n",
    "    db2amp = es.UnaryOperator(type='db2lin', scale=2)\n",
    "    for k in range(len(ess)):\n",
    "        ess[k] = db2amp(ess[k])\n",
    "    stft = librosa.feature.inverse.mel_to_stft(M=ess.T, sr=16000, n_fft=512,norm='slaney', htk=False)\n",
    "    libro = librosa.feature.melspectrogram(sr=16000, S=stft, n_fft=512, hop_length=256, n_mels=96, norm='slaney', htk=False).T\n",
    "    libro = np.log10(1+libro*10000)\n",
    "    new = np.zeros((int(len(libro) / 93) - 1, 187, 96)).astype(np.float32)\n",
    "    for k in range(int(len(libro) / 93) - 1):\n",
    "        new[k]=libro[k*93:k*93+187]\n",
    "    new = np.expand_dims(new, 2)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 1 of 443\n",
      "Processing track 2 of 443\n",
      "Processing track 3 of 443\n",
      "Processing track 4 of 443\n",
      "Processing track 5 of 443\n",
      "Processing track 6 of 443\n",
      "Processing track 7 of 443\n",
      "Processing track 8 of 443\n",
      "Processing track 9 of 443\n",
      "Processing track 10 of 443\n",
      "Processing track 11 of 443\n",
      "Processing track 12 of 443\n",
      "Processing track 13 of 443\n",
      "Processing track 14 of 443\n",
      "Processing track 15 of 443\n",
      "Processing track 16 of 443\n",
      "Processing track 17 of 443\n",
      "Processing track 18 of 443\n",
      "Processing track 19 of 443\n",
      "Processing track 20 of 443\n",
      "Processing track 21 of 443\n",
      "Processing track 22 of 443\n",
      "Processing track 23 of 443\n",
      "Processing track 24 of 443\n",
      "Processing track 25 of 443\n",
      "Processing track 26 of 443\n",
      "Processing track 27 of 443\n",
      "Processing track 28 of 443\n",
      "Processing track 29 of 443\n",
      "Processing track 30 of 443\n",
      "Processing track 31 of 443\n",
      "Processing track 32 of 443\n",
      "Processing track 33 of 443\n",
      "Processing track 34 of 443\n",
      "Processing track 35 of 443\n",
      "Processing track 36 of 443\n",
      "Processing track 37 of 443\n",
      "Processing track 38 of 443\n",
      "Processing track 39 of 443\n",
      "Processing track 40 of 443\n",
      "Processing track 41 of 443\n",
      "Processing track 42 of 443\n",
      "Processing track 43 of 443\n",
      "Processing track 44 of 443\n",
      "Processing track 45 of 443\n",
      "Processing track 46 of 443\n",
      "Processing track 47 of 443\n",
      "Processing track 48 of 443\n",
      "Processing track 49 of 443\n",
      "Processing track 50 of 443\n",
      "Processing track 51 of 443\n",
      "Processing track 52 of 443\n",
      "Processing track 53 of 443\n",
      "Processing track 54 of 443\n",
      "Processing track 55 of 443\n",
      "Processing track 56 of 443\n",
      "Processing track 57 of 443\n",
      "Processing track 58 of 443\n",
      "Processing track 59 of 443\n",
      "Processing track 60 of 443\n",
      "Processing track 61 of 443\n",
      "Processing track 62 of 443\n",
      "Processing track 63 of 443\n",
      "Processing track 64 of 443\n",
      "Processing track 65 of 443\n",
      "Processing track 66 of 443\n",
      "Processing track 67 of 443\n",
      "Processing track 68 of 443\n",
      "Processing track 69 of 443\n",
      "Processing track 70 of 443\n",
      "Processing track 71 of 443\n",
      "Processing track 72 of 443\n",
      "Processing track 73 of 443\n",
      "Processing track 74 of 443\n",
      "Processing track 75 of 443\n",
      "Processing track 76 of 443\n",
      "Processing track 77 of 443\n",
      "Processing track 78 of 443\n",
      "Processing track 79 of 443\n",
      "Processing track 80 of 443\n",
      "Processing track 81 of 443\n",
      "Processing track 82 of 443\n",
      "Processing track 83 of 443\n",
      "Processing track 84 of 443\n",
      "Processing track 85 of 443\n",
      "Processing track 86 of 443\n",
      "Processing track 87 of 443\n",
      "Processing track 88 of 443\n",
      "Processing track 89 of 443\n",
      "Processing track 90 of 443\n",
      "Processing track 91 of 443\n",
      "Processing track 92 of 443\n",
      "Processing track 93 of 443\n",
      "Processing track 94 of 443\n",
      "Processing track 95 of 443\n",
      "Processing track 96 of 443\n",
      "Processing track 97 of 443\n",
      "Processing track 98 of 443\n",
      "Processing track 99 of 443\n",
      "Processing track 100 of 443\n",
      "Processing track 101 of 443\n",
      "Processing track 102 of 443\n",
      "Processing track 103 of 443\n",
      "Processing track 104 of 443\n",
      "Processing track 105 of 443\n",
      "Processing track 106 of 443\n",
      "Processing track 107 of 443\n",
      "Processing track 108 of 443\n",
      "Processing track 109 of 443\n",
      "Processing track 110 of 443\n",
      "Processing track 111 of 443\n",
      "Processing track 112 of 443\n",
      "Processing track 113 of 443\n",
      "Processing track 114 of 443\n",
      "Processing track 115 of 443\n",
      "Processing track 116 of 443\n",
      "Processing track 117 of 443\n",
      "Processing track 118 of 443\n",
      "Processing track 119 of 443\n",
      "Processing track 120 of 443\n",
      "Processing track 121 of 443\n",
      "Processing track 122 of 443\n",
      "Processing track 123 of 443\n",
      "Processing track 124 of 443\n",
      "Processing track 125 of 443\n",
      "Processing track 126 of 443\n",
      "Processing track 127 of 443\n",
      "Processing track 128 of 443\n",
      "Processing track 129 of 443\n",
      "Processing track 130 of 443\n",
      "Processing track 131 of 443\n",
      "Processing track 132 of 443\n",
      "Processing track 133 of 443\n",
      "Processing track 134 of 443\n",
      "Processing track 135 of 443\n",
      "Processing track 136 of 443\n",
      "Processing track 137 of 443\n",
      "Processing track 138 of 443\n",
      "Processing track 139 of 443\n",
      "Processing track 140 of 443\n",
      "Processing track 141 of 443\n",
      "Processing track 142 of 443\n",
      "Processing track 143 of 443\n",
      "Processing track 144 of 443\n",
      "Processing track 145 of 443\n",
      "Processing track 146 of 443\n",
      "Processing track 147 of 443\n",
      "Processing track 148 of 443\n",
      "Processing track 149 of 443\n",
      "Processing track 150 of 443\n",
      "Processing track 151 of 443\n",
      "Processing track 152 of 443\n",
      "Processing track 153 of 443\n",
      "Processing track 154 of 443\n",
      "Processing track 155 of 443\n",
      "Processing track 156 of 443\n",
      "Processing track 157 of 443\n",
      "Processing track 158 of 443\n",
      "Processing track 159 of 443\n",
      "Processing track 160 of 443\n",
      "Processing track 161 of 443\n",
      "Processing track 162 of 443\n",
      "Processing track 163 of 443\n",
      "Processing track 164 of 443\n",
      "Processing track 165 of 443\n",
      "Processing track 166 of 443\n",
      "Processing track 167 of 443\n",
      "Processing track 168 of 443\n",
      "Processing track 169 of 443\n",
      "Processing track 170 of 443\n",
      "Processing track 171 of 443\n",
      "Processing track 172 of 443\n",
      "Processing track 173 of 443\n",
      "Processing track 174 of 443\n",
      "Processing track 175 of 443\n",
      "Processing track 176 of 443\n",
      "Processing track 177 of 443\n",
      "Processing track 178 of 443\n",
      "Processing track 179 of 443\n",
      "Processing track 180 of 443\n",
      "Processing track 181 of 443\n",
      "Processing track 182 of 443\n",
      "Processing track 183 of 443\n",
      "Processing track 184 of 443\n",
      "Processing track 185 of 443\n",
      "Processing track 186 of 443\n",
      "Processing track 187 of 443\n",
      "Processing track 188 of 443\n",
      "Processing track 189 of 443\n",
      "Processing track 190 of 443\n",
      "Processing track 191 of 443\n",
      "Processing track 192 of 443\n",
      "Processing track 193 of 443\n",
      "Processing track 194 of 443\n",
      "Processing track 195 of 443\n",
      "Processing track 196 of 443\n",
      "Processing track 197 of 443\n",
      "Processing track 198 of 443\n",
      "Processing track 199 of 443\n",
      "Processing track 200 of 443\n",
      "Processing track 201 of 443\n",
      "Processing track 202 of 443\n",
      "Processing track 203 of 443\n",
      "Processing track 204 of 443\n",
      "Processing track 205 of 443\n",
      "Processing track 206 of 443\n",
      "Processing track 207 of 443\n",
      "Processing track 208 of 443\n",
      "Processing track 209 of 443\n",
      "Processing track 210 of 443\n",
      "Processing track 211 of 443\n",
      "Processing track 212 of 443\n",
      "Processing track 213 of 443\n",
      "Processing track 214 of 443\n",
      "Processing track 215 of 443\n",
      "Processing track 216 of 443\n",
      "Processing track 217 of 443\n",
      "Processing track 218 of 443\n",
      "Processing track 219 of 443\n",
      "Processing track 220 of 443\n",
      "Processing track 221 of 443\n",
      "Processing track 222 of 443\n",
      "Processing track 223 of 443\n",
      "Processing track 224 of 443\n",
      "Processing track 225 of 443\n",
      "Processing track 226 of 443\n",
      "Processing track 227 of 443\n",
      "Processing track 228 of 443\n",
      "Processing track 229 of 443\n",
      "Processing track 230 of 443\n",
      "Processing track 231 of 443\n",
      "Processing track 232 of 443\n",
      "Processing track 233 of 443\n",
      "Processing track 234 of 443\n",
      "Processing track 235 of 443\n",
      "Processing track 236 of 443\n",
      "Processing track 237 of 443\n",
      "Processing track 238 of 443\n",
      "Processing track 239 of 443\n",
      "Processing track 240 of 443\n",
      "Processing track 241 of 443\n",
      "Processing track 242 of 443\n",
      "Processing track 243 of 443\n",
      "Processing track 244 of 443\n",
      "Processing track 245 of 443\n",
      "Processing track 246 of 443\n",
      "Processing track 247 of 443\n",
      "Processing track 248 of 443\n",
      "Processing track 249 of 443\n",
      "Processing track 250 of 443\n",
      "Processing track 251 of 443\n",
      "Processing track 252 of 443\n",
      "Processing track 253 of 443\n",
      "Processing track 254 of 443\n",
      "Processing track 255 of 443\n",
      "Processing track 256 of 443\n",
      "Processing track 257 of 443\n",
      "Processing track 258 of 443\n",
      "Processing track 259 of 443\n",
      "Processing track 260 of 443\n",
      "Processing track 261 of 443\n",
      "Processing track 262 of 443\n",
      "Processing track 263 of 443\n",
      "Processing track 264 of 443\n",
      "Processing track 265 of 443\n",
      "Processing track 266 of 443\n",
      "Processing track 267 of 443\n",
      "Processing track 268 of 443\n",
      "Processing track 269 of 443\n",
      "Processing track 270 of 443\n",
      "Processing track 271 of 443\n",
      "Processing track 272 of 443\n",
      "Processing track 273 of 443\n",
      "Processing track 274 of 443\n",
      "Processing track 275 of 443\n",
      "Processing track 276 of 443\n",
      "Processing track 277 of 443\n",
      "Processing track 278 of 443\n",
      "Processing track 279 of 443\n",
      "Processing track 280 of 443\n",
      "Processing track 281 of 443\n",
      "Processing track 282 of 443\n",
      "Processing track 283 of 443\n",
      "Processing track 284 of 443\n",
      "Processing track 285 of 443\n",
      "Processing track 286 of 443\n",
      "Processing track 287 of 443\n",
      "Processing track 288 of 443\n",
      "Processing track 289 of 443\n",
      "Processing track 290 of 443\n",
      "Processing track 291 of 443\n",
      "Processing track 292 of 443\n",
      "Processing track 293 of 443\n",
      "Processing track 294 of 443\n",
      "Processing track 295 of 443\n",
      "Processing track 296 of 443\n",
      "Processing track 297 of 443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing track 298 of 443\n",
      "Processing track 299 of 443\n",
      "Processing track 300 of 443\n",
      "Processing track 301 of 443\n",
      "Processing track 302 of 443\n",
      "Processing track 303 of 443\n",
      "Processing track 304 of 443\n",
      "Processing track 305 of 443\n",
      "Processing track 306 of 443\n",
      "Processing track 307 of 443\n",
      "Processing track 308 of 443\n",
      "Processing track 309 of 443\n",
      "Processing track 310 of 443\n",
      "Processing track 311 of 443\n",
      "Processing track 312 of 443\n",
      "Processing track 313 of 443\n",
      "Processing track 314 of 443\n",
      "Processing track 315 of 443\n",
      "Processing track 316 of 443\n",
      "Processing track 317 of 443\n",
      "Processing track 318 of 443\n",
      "Processing track 319 of 443\n",
      "Processing track 320 of 443\n",
      "Processing track 321 of 443\n",
      "Processing track 322 of 443\n",
      "Processing track 323 of 443\n",
      "Processing track 324 of 443\n",
      "Processing track 325 of 443\n",
      "Processing track 326 of 443\n",
      "Processing track 327 of 443\n",
      "Processing track 328 of 443\n",
      "Processing track 329 of 443\n",
      "Processing track 330 of 443\n",
      "Processing track 331 of 443\n",
      "Processing track 332 of 443\n",
      "Processing track 333 of 443\n",
      "Processing track 334 of 443\n",
      "Processing track 335 of 443\n",
      "Processing track 336 of 443\n",
      "Processing track 337 of 443\n",
      "Processing track 338 of 443\n",
      "Processing track 339 of 443\n",
      "Processing track 340 of 443\n",
      "Processing track 341 of 443\n",
      "Processing track 342 of 443\n",
      "Processing track 343 of 443\n",
      "Processing track 344 of 443\n",
      "Processing track 345 of 443\n",
      "Processing track 346 of 443\n",
      "Processing track 347 of 443\n",
      "Processing track 348 of 443\n",
      "Processing track 349 of 443\n",
      "Processing track 350 of 443\n",
      "Processing track 351 of 443\n",
      "Processing track 352 of 443\n",
      "Processing track 353 of 443\n",
      "Processing track 354 of 443\n",
      "Processing track 355 of 443\n",
      "Processing track 356 of 443\n",
      "Processing track 357 of 443\n",
      "Processing track 358 of 443\n",
      "Processing track 359 of 443\n",
      "Processing track 360 of 443\n",
      "Processing track 361 of 443\n",
      "Processing track 362 of 443\n",
      "Processing track 363 of 443\n",
      "Processing track 364 of 443\n",
      "Processing track 365 of 443\n",
      "Processing track 366 of 443\n",
      "Processing track 367 of 443\n",
      "Processing track 368 of 443\n",
      "Processing track 369 of 443\n",
      "Processing track 370 of 443\n",
      "Processing track 371 of 443\n",
      "Processing track 372 of 443\n",
      "Processing track 373 of 443\n",
      "Processing track 374 of 443\n",
      "Processing track 375 of 443\n",
      "Processing track 376 of 443\n",
      "Processing track 377 of 443\n",
      "Processing track 378 of 443\n",
      "Processing track 379 of 443\n",
      "Processing track 380 of 443\n",
      "Processing track 381 of 443\n",
      "Processing track 382 of 443\n",
      "Processing track 383 of 443\n",
      "Processing track 384 of 443\n",
      "Processing track 385 of 443\n",
      "Processing track 386 of 443\n",
      "Processing track 387 of 443\n",
      "Processing track 388 of 443\n",
      "Processing track 389 of 443\n",
      "Processing track 390 of 443\n",
      "Processing track 391 of 443\n",
      "Processing track 392 of 443\n",
      "Processing track 393 of 443\n",
      "Processing track 394 of 443\n",
      "Processing track 395 of 443\n",
      "Processing track 396 of 443\n",
      "Processing track 397 of 443\n",
      "Processing track 398 of 443\n",
      "Processing track 399 of 443\n",
      "Processing track 400 of 443\n",
      "Processing track 401 of 443\n",
      "Processing track 402 of 443\n",
      "Processing track 403 of 443\n",
      "Processing track 404 of 443\n",
      "Processing track 405 of 443\n",
      "Processing track 406 of 443\n",
      "Processing track 407 of 443\n",
      "Processing track 408 of 443\n",
      "Processing track 409 of 443\n",
      "Processing track 410 of 443\n",
      "Processing track 411 of 443\n",
      "Processing track 412 of 443\n",
      "Processing track 413 of 443\n",
      "Processing track 414 of 443\n",
      "Processing track 415 of 443\n",
      "Processing track 416 of 443\n",
      "Processing track 417 of 443\n",
      "Processing track 418 of 443\n",
      "Processing track 419 of 443\n",
      "Processing track 420 of 443\n",
      "Processing track 421 of 443\n",
      "Processing track 422 of 443\n",
      "Processing track 423 of 443\n",
      "Processing track 424 of 443\n",
      "Processing track 425 of 443\n",
      "Processing track 426 of 443\n",
      "Processing track 427 of 443\n",
      "Processing track 428 of 443\n",
      "Processing track 429 of 443\n",
      "Processing track 430 of 443\n",
      "Processing track 431 of 443\n",
      "Processing track 432 of 443\n",
      "Processing track 433 of 443\n",
      "Processing track 434 of 443\n",
      "Processing track 435 of 443\n",
      "Processing track 436 of 443\n",
      "Processing track 437 of 443\n",
      "Processing track 438 of 443\n",
      "Processing track 439 of 443\n",
      "Processing track 440 of 443\n",
      "Processing track 441 of 443\n",
      "Processing track 442 of 443\n",
      "Processing track 443 of 443\n"
     ]
    }
   ],
   "source": [
    "#'nearest'  'bilinear', 'bicubic', , 'area', 'trilinear'\n",
    "if not os.path.isfile('train_embeddings_stft.npy'):\n",
    "    i=0\n",
    "    train_embeddings = []\n",
    "    for track in train_dataset:\n",
    "        i+=1\n",
    "        print('Processing track '+str(i)+' of '+str(len(train_dataset)))\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict_STFT(melspectrogram(resample(track[0].numpy()[0]))))\n",
    "        output = predict(in_pool)\n",
    "        train_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    train_embeddings = np.array(train_embeddings)\n",
    "    np.save('train_embeddings_stft.npy', train_embeddings)\n",
    "    \n",
    "    val_embeddings = []\n",
    "    for track in val_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict_STFT(melspectrogram(resample(track[0].numpy()[0]))))\n",
    "        output = predict(in_pool)\n",
    "        val_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    val_embeddings = np.array(val_embeddings)\n",
    "    np.save('val_embeddings_stft.npy', val_embeddings)\n",
    "    \n",
    "    test_embeddings = []\n",
    "    for track in test_dataset:\n",
    "        in_pool = Pool()\n",
    "        in_pool.set('model/Placeholder', adapt_melonInput_TensorflowPredict_STFT(melspectrogram(resample(track[0].numpy()[0]))))\n",
    "        output = predict(in_pool)\n",
    "        test_embeddings.append(output['model/dense/BiasAdd'][:,0,0,:])\n",
    "    test_embeddings = np.array(test_embeddings)\n",
    "    np.save('test_embeddings_stft.npy', test_embeddings)    \n",
    "\n",
    "else:\n",
    "    train_embeddings=np.load('train_embeddings_stft.npy')\n",
    "    val_embeddings=np.load('val_embeddings_stft.npy')\n",
    "    test_embeddings=np.load('test_embeddings_stft.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 2.4730193614959717. Val Loss = 2.4873480796813965.\n",
      "Epoch 100: Train Loss = 1.8230901956558228. Val Loss = 1.9641129970550537.\n",
      "Epoch 200: Train Loss = 1.5462123155593872. Val Loss = 1.7267212867736816.\n",
      "Epoch 300: Train Loss = 1.3712682723999023. Val Loss = 1.586881160736084.\n",
      "Epoch 400: Train Loss = 1.2451542615890503. Val Loss = 1.4988665580749512.\n",
      "Epoch 500: Train Loss = 1.160767674446106. Val Loss = 1.4396755695343018.\n",
      "Epoch 600: Train Loss = 1.0896888971328735. Val Loss = 1.39529287815094.\n",
      "Epoch 700: Train Loss = 1.0339666604995728. Val Loss = 1.361782193183899.\n",
      "Epoch 800: Train Loss = 0.9949813485145569. Val Loss = 1.3371638059616089.\n",
      "Epoch 900: Train Loss = 0.9583620429039001. Val Loss = 1.316237211227417.\n",
      "Epoch 1000: Train Loss = 0.9327408075332642. Val Loss = 1.30291748046875.\n",
      "Epoch 1100: Train Loss = 0.9289027452468872. Val Loss = 1.3029148578643799.\n",
      "Epoch 1200: Train Loss = 0.9297040104866028. Val Loss = 1.3029118776321411.\n",
      "Epoch 1300: Train Loss = 0.9337382912635803. Val Loss = 1.3029097318649292.\n",
      "Epoch 1400: Train Loss = 0.9295777082443237. Val Loss = 1.3029080629348755.\n",
      "Epoch 1500: Train Loss = 0.9316080212593079. Val Loss = 1.3029066324234009.\n",
      "Epoch 1600: Train Loss = 0.9307621121406555. Val Loss = 1.302903652191162.\n",
      "Epoch 1700: Train Loss = 0.9363124966621399. Val Loss = 1.302901029586792.\n",
      "Epoch 1800: Train Loss = 0.937403678894043. Val Loss = 1.3029001951217651.\n",
      "Epoch 1900: Train Loss = 0.9369409680366516. Val Loss = 1.302898645401001.\n",
      "Best validation loss :1.3023861646652222\n"
     ]
    }
   ],
   "source": [
    "stft_net = train_test(train_embeddings, val_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.41491937637329"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model        | Loss           | GTZAN accuracy  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "| Random embeddings      | 2.31 | 9.37% |\n",
    "| Random musiCNN      | 1.88 | 40,58% |\n",
    "| musiCNN waveform      |    0.67   |   80.50% |\n",
    "| musiCNN linear interpolation | 0.92      |    74.57% |\n",
    "| <strong>musiCNN nearest interpolation</strong> | <strong>0.87 </strong>     |   <strong> 77.28% </strong>|\n",
    "| musiCNN bilinear interpolation | 1.09     |    69.30% |\n",
    "| musiCNN bicubic interpolation |   0.94   |    72.83% |\n",
    "| musiCNN bicubic aligned_corners |   0.95   |    74.23% |\n",
    "| musiCNN area interpolation |      0.97 |    75.04% |\n",
    "| musiCNN trilinear interpolation |  1.04     |    70.40% |\n",
    "| musiCNN MEL_to_audio librosa |  2.58     |    18.75% |\n",
    "| musiCNN MEL_to_STFT librosa |    1.30   |    63.41% |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melon_venv",
   "language": "python",
   "name": "melon_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
